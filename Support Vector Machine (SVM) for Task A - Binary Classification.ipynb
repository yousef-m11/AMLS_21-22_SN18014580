{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359e1f9d",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Systems (MLS-1) - ELEC0134\n",
    "\n",
    "# Final Assignment - Classification of Tumours\n",
    "\n",
    "## Task A - Binary Classification using Support Vector Machines (SVM)\n",
    "\n",
    "## Completed by Student Number - 18014580"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0507318",
   "metadata": {},
   "source": [
    "This is a Jupyter Notebook submitted as part of the final assignment for the Applied Machine Learning Systems (MLS-1) coursework which involves tumor classification and identification.\n",
    "\n",
    "This particular notebook tests the SVM method using the SVC model from the sklearn library on Task A to find the accuracy of using support vector machines classification for this particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af10ba",
   "metadata": {},
   "source": [
    "### Importing different packages\n",
    "\n",
    "Initially, we must import the different packages needed for this task. The packages required to implement suport vector machines for this binary task can be found in pandas, sklearn (scikit-learn), skimage (scikit-image), and numpy. Please ensure these are installed in your virtualenv before running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ceb0527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports carried out successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "from skimage import io\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# import tensorflow as tf\n",
    "#from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All imports carried out successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff8807",
   "metadata": {},
   "source": [
    "### Loading the data from the data sets\n",
    "\n",
    "In this cell we are using read_csv to load the labels for each image into a dataframe. We then display the dataframe to ensure the data from the .csv file was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e31a55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Loading the CSV file 'label' containing the different labels for each MRI Scan\n",
    "\n",
    "tumour_labels = pd.read_csv('./dataset/label.csv')\n",
    "print(tumour_labels.shape) #Outputs array with the shape of the dataframe to ensure all images, filenames and labels loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be61086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMAGE_0000.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMAGE_0001.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMAGE_0002.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMAGE_0003.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMAGE_0004.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>IMAGE_2995.jpg</td>\n",
       "      <td>no_tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>IMAGE_2996.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>IMAGE_2997.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>IMAGE_2998.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>IMAGE_2999.jpg</td>\n",
       "      <td>tumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_name     label\n",
       "0     IMAGE_0000.jpg     tumor\n",
       "1     IMAGE_0001.jpg  no_tumor\n",
       "2     IMAGE_0002.jpg     tumor\n",
       "3     IMAGE_0003.jpg     tumor\n",
       "4     IMAGE_0004.jpg     tumor\n",
       "...              ...       ...\n",
       "2995  IMAGE_2995.jpg  no_tumor\n",
       "2996  IMAGE_2996.jpg     tumor\n",
       "2997  IMAGE_2997.jpg     tumor\n",
       "2998  IMAGE_2998.jpg     tumor\n",
       "2999  IMAGE_2999.jpg     tumor\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumour_labels #Displaying data frame to visually ensure data loaded correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f40ca",
   "metadata": {},
   "source": [
    "### Printing out dataset to ensure labels changed accordingly\n",
    "\n",
    "This is a binary classification task, so in the cells below, we modify the data frame by locating all the images whose label is not \"no_tumor\" and setting them to tumor rather than having them as the types of tumor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd063398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change anything in the label column that is not equal to \"no_tumor\" to \"tumor\" rather than the type of tumor\n",
    "tumour_labels.loc[tumour_labels['label']!= 'no_tumor', 'label'] = 'tumor' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140a3ea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tumour_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\YOUSEF~1\\AppData\\Local\\Temp/ipykernel_5560/2205985441.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtumour_labels\u001b[0m \u001b[1;31m#Displaying data frame to visually ensure labels changed as specified in cell above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tumour_labels' is not defined"
     ]
    }
   ],
   "source": [
    "tumour_labels #Displaying data frame to visually ensure labels changed as specified in cell above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aea62b",
   "metadata": {},
   "source": [
    "### Adding numeric representation to the data frame¶\n",
    "\n",
    "In the cells below, we add another column to the data frame and assign a numeric value label to each label. Since our problem is binary, the numeric label can only be 1 or 0.\n",
    "\n",
    "If the label indicates \"tumor\" it is assigned a numeric label 1, and if the label does not indicate a tumour \"no_tumor\" it is assigned the numeric label 0. It also increases adaptability or convenience of the code if deep-learning models were to be used to have numeric label rather than a text label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['no_tumor', 'tumor']\n",
    "for CLASS in classes:\n",
    "    tumour_labels.loc[tumour_labels['label'] == CLASS, 'numeric label'] = classes.index(CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28dfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumour_labels #Displaying dataframe to ensure new column created and values are being assigned properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19b398",
   "metadata": {},
   "source": [
    "### Choosing mode and loading the images\n",
    "\n",
    "In the cell below, we give the user the option to select whether or not to convert the images from RGB to greyscale as their could be different in runtime and accuracy. Any such results will be reported in the written report. Below are some average metrics for RGB and Greyscale.\n",
    "\n",
    "In the runs carried out, the average metrics for each are:\n",
    "\n",
    "RGB (Accuracy, Time Taken ...)\n",
    "Grayscale (Accuracy, Time Taken ... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbe49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('As default, this program loads images with their RGB channels. Would you like to change the images to grayscale? \\n')\n",
    "color_mode = input('Please type in Yes or No: ')\n",
    "\n",
    "if color_mode.lower().startswith(\"y\"):\n",
    "    print(\"\\n You selected Yes. The images will be loaded as Grayscale images.\")\n",
    "elif color_mode.lower().startswith(\"n\"):\n",
    "    print(\"\\n You selected No. The images will be loaded with their RGB channels.\")\n",
    "else:\n",
    "    print(\"\\n Invalid choice. Please select Yes or No.\")\n",
    "    color_mode = input('\\n Please type in Yes or No: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfef17",
   "metadata": {},
   "source": [
    "In the cell below, we load the image files using the imread functions from the scikit-image package. We convert the images to numpy arrays before appending them to a list. This list of arrays is then converted to a numpy array of arrays to allow us to print the shape to verify all the images have been loaded.\n",
    "\n",
    "This cell also uses datetime.now() to output the time elapsed to load the image set. This was used to compare efficiency of different imread functions from different packages including skimage, cv2 etc. In the end, skimage was chosen as it produced slightly favourable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189f7c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#Uncomment to verify contents of the directory loaded\n",
    "\n",
    "#dirname = './dataset/image'\n",
    "#print(listdir(dirname))\n",
    "\n",
    "#Code used to test timing\n",
    "\n",
    "start = datetime.now() #Stores the time at which loading starts\n",
    "\n",
    "images = [] #An empty list is created\n",
    "\n",
    "#If statement uses user input color_mode to decide whether to convert images to greyscale or not before populating list\n",
    "#The for loops reads all images from the directory as listdir allows it loop through name of all files in the directory\n",
    "\n",
    "if color_mode.lower().startswith(\"n\"):\n",
    "    for file in listdir('./dataset/image'): \n",
    "        img = io.imread('./dataset/image/' + file) \n",
    "        img = np.array(img) #Converting image loaded to a numpy array\n",
    "        images.append(img) #Appending the img as a numpy array into the list images\n",
    "        \n",
    "        #This can be uncommented if we want to show all the images but data is too large so we usually don't\n",
    "        #plt.figure()\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "elif color_mode.lower().startswith(\"y\"):\n",
    "    for file in listdir('./dataset/image'):\n",
    "        img = io.imread('./dataset/image/' + file)\n",
    "        greyimg = rgb2gray(img) #Converting each image to grayscale \n",
    "        greyimg = np.array(greyimg) #Converting image loaded to a numpy array\n",
    "        images.append(greyimg) #Appending the img as a numpy array into the list images\n",
    "        \n",
    "        #plt.figure()\n",
    "        #plt.imshow(img)\n",
    "    \n",
    "#Marking the end of the code\n",
    "end = datetime.now()\n",
    "elapsed = end - start #Calculating time elapsed while comparing different packages used to load images\n",
    "print('The time elapsed to load the images was: ', + elapsed) \n",
    "\n",
    "#The red colormap applied will only appear if it is a grayscalew image. The image is chosen randomly to be images[45]\n",
    "io.imshow(np.array(images[45]), cmap='Reds') #Verifying visually if the image is greyscale or not by applying red colormap\n",
    "\n",
    "print(np.array(images).shape) #Converting list images to a numpy array before outputting shape to verify "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133dc06",
   "metadata": {},
   "source": [
    "### Splitting the data into training and testing data\n",
    "\n",
    "In the cells below, we use train_test_split from the model_selection part of the sklearn package. This splits the data into training and testing data before we train the model. The testing data is left unseen so we can test our trained model using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c436772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 512, 512, 3)\n",
      "(750, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(images) #Set X to contain the array of images\n",
    "Y = tumour_labels['numeric label'] #Set Y to contain the corresponding numeric labels of each image\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X,Y, random_state = 0) #Set random_state to 0 for reproducibility\n",
    "\n",
    "print(xTrain.shape) #Printing the shape of xTrain to veryify data was split correctly\n",
    "print(xTest.shape) #Printing the shape of xTest to verify  data was split correctly\n",
    "train_size = xTrain.shape[0]\n",
    "test_size = xTest.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b4eae0",
   "metadata": {},
   "source": [
    "### Reshaping xTrain and xTest for use in ML models and verifying the reshape\n",
    "\n",
    "These cells reshape xTrain and xTest to 2-dimensional arrays and verifies they have been correctly reshaped depending on whether or not they were converted to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ce44395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping xTrain and xTest each to 2-dimensional arrays to allow them to be input into models such as Logistic Reg and SVMs\n",
    "\n",
    "#If statement to control reshaping of xTrain and xTest dependent if using RGB or Grayscale\n",
    "#If RGB then .shape arrays will have 4 elements, so we reshape using [1], [2] and [3] from xTrain.shape\n",
    "#Otherwise, if Grayscale .shape arrays will only have 3 elements so we reshape using only [1] and [2] as there is no [3]\n",
    "\n",
    "if len(xTrain.shape) == 4:\n",
    "    xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1]*xTrain.shape[2]*xTrain.shape[3])\n",
    "    xTest = xTest.reshape(xTest.shape[0], xTest.shape[1]*xTest.shape[2]*xTest.shape[3])\n",
    "elif len(xTrain.shape) == 3:\n",
    "    xTrain = xTrain.reshape(xTrain.shape[0], xTrain.shape[1]*xTrain.shape[2])\n",
    "    xTest = xTest.reshape(xTest.shape[0], xTest.shape[1]*xTest.shape[2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a2569dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 786432)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTrain.shape #Visually verifying xTrain has been reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d5c3495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 786432)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTest.shape #Visually verifying xTest has been reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd428cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain reshaped correctly\n",
      "xTest reshaped correctly\n"
     ]
    }
   ],
   "source": [
    "if color_mode.lower().startswith(\"n\"):\n",
    "    if xTrain.shape[0] == train_size and xTrain.shape[1] == 512*512*3:\n",
    "        print('xTrain reshaped correctly')\n",
    "    else: print('xTrain reshaped incorrectly')\n",
    "    if xTest.shape[0] == test_size and xTest.shape[1] == 512*512*3:\n",
    "        print('xTest reshaped correctly')\n",
    "    else: print('xTest reshaped incorrectly')\n",
    "elif color_mode.lower().startswith(\"y\"):\n",
    "    if xTrain.shape[0] == train_size and xTrain.shape[1] == 512*512:\n",
    "        print('xTrain reshaped correctly')\n",
    "    else: print('xTrain reshaped incorrectly')\n",
    "    if xTest.shape[0] == test_size and xTest.shape[1] == 512*512:\n",
    "        print('xTest reshaped correctly')\n",
    "    else: print('xTest reshaped incorrectly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29d875",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f83c43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_svmlinear = SVC(kernel='linear')\n",
    "#model2_svmpoly\n",
    "#model3_svmrbf\n",
    "model.fit(xTrain, yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_Pred = LogRegClassification(xTrain, yTrain, xTest)\n",
    "y_Pred = model.predict(xTest)\n",
    "print('Accuracy on test set: '+str(accuracy_score(yTest,y_Pred)))\n",
    "print(classification_report(yTest,y_Pred))#text report showing the main classification metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc9199",
   "metadata": {},
   "source": [
    "### Testing and reporting new accuracy score using updated test set uploaded on XX Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574558f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00496b56",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix and then show which images were misclassified and see if they are the same each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a9069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2139139c",
   "metadata": {},
   "source": [
    "### See if any specific techniques can be used to help with the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a558113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67a9d8e3",
   "metadata": {},
   "source": [
    "### Training loss, validation loss and hyperpara tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8bcce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e535fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
