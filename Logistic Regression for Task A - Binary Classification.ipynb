{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55991b3",
   "metadata": {},
   "source": [
    "# Applied Machine Learning Systems (MLS-1) - ELEC0134\n",
    "\n",
    "# Final Assignment - Classification of Tumours\n",
    "\n",
    "## Task A - Binary Classification using Logistic Regression\n",
    "\n",
    "## Completed by Student Number - 18014580"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29924356",
   "metadata": {},
   "source": [
    "This is a Jupyter Notebook submitted as part of the final assignment for the Applied Machine Learning Systems (MLS-1) coursework which involves tumor classification and identification.\n",
    "\n",
    "This particular notebook tests the logistic regression method on Task A to find the accuracy of logistic regression for this particular task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516cd89",
   "metadata": {},
   "source": [
    "### Importing different packages\n",
    "\n",
    "Initially, we must import the different packages needed for this task. The packages required to implement logistic regression for this binary task are pandas, sklearn, numpy and scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6261ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports carried out successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from skimage import io\n",
    "from skimage.io import imread, imshow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"All imports carried out successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5401ae",
   "metadata": {},
   "source": [
    "### Loading the data from the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ca063e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "#Loading the CSV file containing the labels\n",
    "tumour_labels = pd.read_csv('./dataset/label.csv')\n",
    "print(tumour_labels.shape) #outputs array with the number of features + feature number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf2bdb",
   "metadata": {},
   "source": [
    "### Loading the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f2bfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "#example of loading one image\n",
    "#image = imread('./dataset/image/IMAGE_0009.jpg')\n",
    "#plt.imshow(image)\n",
    "\n",
    "#image2 = imread('./dataset/image/IMAGE_0010.jpg')\n",
    "#plt.figure()\n",
    "#plt.imshow(image2)\n",
    "#imarr = np.array(image2)\n",
    "#plt.figure()\n",
    "#plt.imshow(imarr)\n",
    "\n",
    "images = []\n",
    "#x=0\n",
    "#t = time.process_time()\n",
    "\n",
    "#dirname = './dataset/image'\n",
    "#print(listdir(dirname))\n",
    "\n",
    "#start = datetime.now()\n",
    "#start = datetime.now().time()\n",
    "#print('start: ')\n",
    "#print(start)\n",
    "\n",
    "for file in listdir('./dataset/image'):\n",
    "\n",
    "    img = io.imread('./dataset/image/' + file)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    #print(x)\n",
    "    #x += 1\n",
    "    img = np.array(img)\n",
    "    images.append(img)\n",
    "\n",
    "print(np.array(images).shape)\n",
    "    \n",
    "#end = datetime.now()\n",
    "#end = datetime.now().time()\n",
    "#print('end: ')\n",
    "#print(end)\n",
    "#elapsed = end - start\n",
    "#print(elapsed)\n",
    "#current = elapsed\n",
    "    \n",
    "#ETA = time.process_time() - t\n",
    "#print(ETA)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99bf40a",
   "metadata": {},
   "source": [
    "### Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecce320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 512, 512, 3)\n",
      "(750, 512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(images)\n",
    "Y = tumour_labels['label']\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X,Y)\n",
    "\n",
    "print(xTrain.shape)\n",
    "print(xTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609c39f5",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cede4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fff100",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
